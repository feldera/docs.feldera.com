"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[1694],{28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>i});var r=n(96540);const a={},s=r.createContext(a);function o(e){const t=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),r.createElement(s.Provider,{value:t},e.children)}},62822:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"connectors/sinks/delta","title":"Delta Lake output connector","description":"Delta Lake is a popular open table format based on Parquet files.","source":"@site/docs/connectors/sinks/delta.md","sourceDirName":"connectors/sinks","slug":"/connectors/sinks/delta","permalink":"/connectors/sinks/delta","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"HTTP","permalink":"/connectors/sinks/http"},"next":{"title":"Kafka","permalink":"/connectors/sinks/kafka"}}');var a=n(74848),s=n(28453);const o={},i="Delta Lake output connector",l={},c=[{value:"Support for delete operations",id:"support-for-delete-operations",level:2},{value:"Delta Lake output connector configuration",id:"delta-lake-output-connector-configuration",level:2},{value:"Storage parameters",id:"storage-parameters",level:3},{value:"Data type mapping",id:"data-type-mapping",level:2},{value:"The small file problem and output buffer configuration",id:"the-small-file-problem-and-output-buffer-configuration",level:2},{value:"Example usage",id:"example-usage",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"delta-lake-output-connector",children:"Delta Lake output connector"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://delta.io/",children:"Delta Lake"})," is a popular open table format based on Parquet files.\nIt is typically used with the ",(0,a.jsx)(t.a,{href:"https://spark.apache.org/",children:"Apache Spark"})," runtime.\nData in a Delta Lake is organized in tables, stored in\na file system or an object stores like ",(0,a.jsx)(t.a,{href:"https://aws.amazon.com/s3/",children:"AWS S3"}),",\n",(0,a.jsx)(t.a,{href:"https://cloud.google.com/storage",children:"Google GCS"}),", or\n",(0,a.jsx)(t.a,{href:"https://azure.microsoft.com/en-us/products/storage/blobs",children:"Azure Blob Storage"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["The Delta Lake output connector does not yet support ",(0,a.jsx)(t.a,{href:"/pipelines/fault-tolerance",children:"fault\ntolerance"}),"."]}),"\n",(0,a.jsx)(t.h2,{id:"support-for-delete-operations",children:"Support for delete operations"}),"\n",(0,a.jsx)(t.p,{children:"The Delta Lake format does not support efficient real-time deletes and updates.\nTo delete a record from a Delta table, one must first locate the record, which\noften requires an expensive table scan. This limitation makes it inefficient to\ndirectly write the output of a Feldera pipeline, which consists of both inserts\nand deletes, to a Delta table."}),"\n",(0,a.jsx)(t.p,{children:"To address this issue, the Delta Lake connector transforms both inserts and deletes\ninto table records with additional metadata columns that describe the type and order\nof operations. Specifically, the connector adds the following columns to the output\nDelta table:"}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{children:"Column"}),(0,a.jsx)(t.th,{children:"Type"}),(0,a.jsx)(t.th,{children:"Description"})]})}),(0,a.jsxs)(t.tbody,{children:[(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:(0,a.jsx)(t.code,{children:"__feldera_op"})}),(0,a.jsx)(t.td,{children:(0,a.jsx)(t.code,{children:"VARCHAR"})}),(0,a.jsxs)(t.td,{children:["Operation that this record represents: ",(0,a.jsx)(t.code,{children:"i"}),' for "insert" or ',(0,a.jsx)(t.code,{children:"d"}),' for "delete".']})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:(0,a.jsx)(t.code,{children:"__feldera_ts"})}),(0,a.jsx)(t.td,{children:(0,a.jsx)(t.code,{children:"BIGINT"})}),(0,a.jsx)(t.td,{children:"Timestamp of the update, used to establish the order of updates. Updates with smaller timestamps are applied before those with larger timestamps."})]})]})]}),"\n",(0,a.jsxs)(t.p,{children:["Effectively, we treat the table as a change log, where every record corresponds to\neither an insert or delete operation. The user can run a periodic Spark job to\nincorporate these change log into another Delta table, using the SQL ",(0,a.jsx)(t.code,{children:"MERGE INTO"})," operation."]}),"\n",(0,a.jsx)(t.h2,{id:"delta-lake-output-connector-configuration",children:"Delta Lake output connector configuration"}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{children:"Parameter"}),(0,a.jsx)(t.th,{children:"Description"})]})}),(0,a.jsxs)(t.tbody,{children:[(0,a.jsxs)(t.tr,{children:[(0,a.jsxs)(t.td,{children:[(0,a.jsx)(t.code,{children:"uri"}),"*"]}),(0,a.jsxs)(t.td,{children:["Table URI, e.g., ",(0,a.jsx)(t.code,{children:'"s3://feldera-fraud-detection-data/feature_train"'}),"."]})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsxs)(t.td,{children:[(0,a.jsx)(t.code,{children:"mode"}),"*"]}),(0,a.jsx)(t.td,{children:"Determines how the Delta table connector handles an existing table at the target location. Options:"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{}),(0,a.jsxs)(t.td,{children:["- ",(0,a.jsx)(t.code,{children:"append"}),": New updates will be appended to the existing table at the target location."]})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{}),(0,a.jsxs)(t.td,{children:["- ",(0,a.jsx)(t.code,{children:"truncate"}),": Existing table at the specified location will be truncated. The connector achieves this by outputting delete actions for all files in the latest snapshot of the table."]})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{}),(0,a.jsxs)(t.td,{children:["- ",(0,a.jsx)(t.code,{children:"error_if_exists"}),": If a table exists at the specified location, the operation will fail."]})]})]})]}),"\n",(0,a.jsx)(t.p,{children:"[*]: Required fields"}),"\n",(0,a.jsx)(t.h3,{id:"storage-parameters",children:"Storage parameters"}),"\n",(0,a.jsx)(t.p,{children:"Additional configuration options are defined for specific storage backends.  Refer to\nbackend-specific documentation for details:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html",children:"Amazon S3 options"})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html",children:"Azure Blob Storage options"})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html",children:"Google Cloud Storage options"})}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"data-type-mapping",children:"Data type mapping"}),"\n",(0,a.jsxs)(t.p,{children:["See ",(0,a.jsx)(t.a,{href:"/connectors/sources/delta/#data-type-mapping",children:"source connector documentation"})," for DeltaLake to Feldera SQL\ntype mapping."]}),"\n",(0,a.jsx)(t.h2,{id:"the-small-file-problem-and-output-buffer-configuration",children:"The small file problem and output buffer configuration"}),"\n",(0,a.jsx)(t.p,{children:"By default a Feldera pipeline sends a batch of changes to the output transport\nfor each batch of input updates it processes.  This can result in a stream of\nsmall updates, which is normal and even preferable for output transports like\nKafka; however it can cause problems for the Delta Lake format by creating a large\nnumber of small files."}),"\n",(0,a.jsx)(t.p,{children:"The output buffer mechanism is designed to solve this problem by decoupling the\nrate at which the pipeline pushes changes to the output transport from the rate\nof input changes.  It works by accumulating updates inside the pipeline\nfor up to a user-defined period of time or until accumulating a user-defined number\nof updates and writing them to the Delta Table as a small number of large files."}),"\n",(0,a.jsxs)(t.p,{children:["See ",(0,a.jsx)(t.a,{href:"/connectors#configuring-the-output-buffer",children:"output buffer"})," for details on configuring the output buffer mechanism."]}),"\n",(0,a.jsx)(t.h2,{id:"example-usage",children:"Example usage"}),"\n",(0,a.jsx)(t.p,{children:"Create a Delta Lake output connector that writes a stream of updates to a table\nstored in an S3 bucket, truncating any existing contents of the table."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-sql",children:'CREATE VIEW V\nWITH (\n \'connectors\' = \'[{\n    "transport": {\n      "name": "delta_table_output",\n      "config": {\n        "uri": "s3://feldera-fraud-detection-demo/feature_train",\n        "mode": "truncate",\n        "aws_access_key_id": <AWS_ACCESS_KEY_ID>,\n        "aws_secret_access_key": <AWS_SECRET_ACCESS_KEY>,\n        "aws_region": "us-east-1"\n      }\n    },\n    "enable_output_buffer": true,\n    "max_output_buffer_time_millis": 10000\n }]\'\n)\nAS SELECT * FROM my_table;\n'})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);