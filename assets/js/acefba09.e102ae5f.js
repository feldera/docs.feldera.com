"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[2568],{21457:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"connectors/sources/debezium","title":"Debezium input connector","description":"This page describes configuration options specific to the Debezium source connector.","source":"@site/docs/connectors/sources/debezium.md","sourceDirName":"connectors/sources","slug":"/connectors/sources/debezium","permalink":"/connectors/sources/debezium","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Google Pub/Sub","permalink":"/connectors/sources/pubsub"},"next":{"title":"PostgreSQL","permalink":"/connectors/sources/postgresql"}}');var a=o(74848),r=o(28453);const s={},i="Debezium input connector",c={},l=[{value:"Step 1: Configure your database to work with Debezium",id:"step-1-configure-your-database-to-work-with-debezium",level:2},{value:"Step 2: Create Kafka Connect input connector",id:"step-2-create-kafka-connect-input-connector",level:2},{value:"Examples",id:"examples",level:3},{value:"Step 3: Create Feldera input connector",id:"step-3-create-feldera-input-connector",level:2},{value:"JSON",id:"json",level:3},{value:"Avro",id:"avro",level:3},{value:"Table schema mapping",id:"table-schema-mapping",level:2},{value:"JSON columns",id:"json-columns",level:3},{value:"Additional resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"debezium-input-connector",children:"Debezium input connector"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["This page describes configuration options specific to the Debezium source connector.\nSee ",(0,a.jsx)(n.a,{href:"/connectors/",children:"top-level connector documentation"})," for general information\nabout configuring input and output connectors."]})}),"\n",(0,a.jsxs)(n.p,{children:["Debezium is a widely-used ",(0,a.jsx)(n.strong,{children:"Change Data Capture"})," (CDC) technology that streams real-time changes from databases such\nas PostgreSQL, MySQL, and Oracle to Kafka topics. Feldera can consume these change streams as inputs. We support\nDebezium streams encoded in both ",(0,a.jsx)(n.a,{href:"/formats/json",children:"JSON"})," and ",(0,a.jsx)(n.a,{href:"/formats/avro",children:"Avro"})," formats. Synchronizing\na set of database tables with Feldera using Debezium involves three steps:"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#step-1-configure-your-database-to-work-with-debezium",children:(0,a.jsx)(n.strong,{children:"Configure your database to work with Debezium"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#step-2-create-kafka-connect-input-connector",children:(0,a.jsx)(n.strong,{children:"Create the Kafka Connect input connector"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#step-3-create-feldera-input-connector",children:(0,a.jsx)(n.strong,{children:"Create Feldera input connectors"})})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"step-1-configure-your-database-to-work-with-debezium",children:"Step 1: Configure your database to work with Debezium"}),"\n",(0,a.jsxs)(n.p,{children:["Each database type requires specific configuration settings to integrate with Debezium.\nFor detailed instructions on configuring your database, refer to the\n",(0,a.jsx)(n.a,{href:"https://debezium.io/documentation/reference/",children:"Debezium documentation"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"step-2-create-kafka-connect-input-connector",children:"Step 2: Create Kafka Connect input connector"}),"\n",(0,a.jsxs)(n.p,{children:["Debezium is built on top of\n",(0,a.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/connect/index.html",children:"Kafka Connect"}),".  You will need\nto install Kafka Connect along with a Debezium plugin for your database.\nNext you will need to use the Kafka Connect REST API to create a source connector to stream\nchanges from the database change log to a Kafka topic."]}),"\n",(0,a.jsxs)(n.p,{children:["Refer to the ",(0,a.jsx)(n.a,{href:"https://debezium.io/documentation/reference/",children:"Debezium documentation"})," to configure\nthe connector according to your requirements, including database connectivity and selecting the\nsubset of tables to synchronize. Debezium can produce data change events in either JSON or Avro\nformats, both of which are supported by Feldera (see ",(0,a.jsx)(n.a,{href:"#examples",children:"examples"})," below). When using the\nJSON format, ensure the following Kafka Connect properties are set to enable Feldera to correctly\ndeserialize data change events from JSON:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Set ",(0,a.jsx)(n.code,{children:'"decimal.handling.mode": "string"'})," - required for Feldera to correctly parse decimal values."]}),"\n",(0,a.jsxs)(n.li,{children:["In addition, for Postgres, Oracle, and SQL Server set ",(0,a.jsx)(n.code,{children:'"time.precision.mode": "connect"'})]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,a.jsx)(n.p,{children:"Create a Debezium connector to read changes from a Postgres database into JSON-encoded Kafka topics:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'curl -i -X \\\n  POST -H "Accept:application/json" -H "Content-Type:application/json" \\\n  [KAFKA CONNECT HOSTNAME:PORT]/connectors/ -d \\\n  \'{\n      "name": "my-connector",\n      "config": {\n          "connector.class": "io.debezium.connector.postgresql.PostgresConnector",\n          "database.hostname": "[POSTGRES HOST NAME]",\n          "database.port": "[POSTGRES PORT]",\n          "database.user": "[DEBEZIUM USERNAME]",\n          "database.password": "[DEBEZIUM PASSWORD]",\n          "database.dbname": "[DATABASE NAME]",\n          "table.include.list": "[TABLE LIST]",\n          "topic.prefix": "[KAFKA TOPIC PREFIX]",\n          "decimal.handling.mode": "string",\n          "time.precision.mode": "connect"\n      }\n  }\'\n'})}),"\n",(0,a.jsx)(n.p,{children:"Create a Debezium connector to read changes from a Postgres database into Avro-encoded Kafka topics.  Note that connector configuration must include a schema registry URL, used to publish\nAvro message schemas used to encode Debezium Kafka messages."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'curl -i -X \\\n  POST -H "Accept:application/json" -H "Content-Type:application/json" \\\n  [KAFKA CONNECT HOSTNAME:PORT]/connectors/ -d \\\n  \'{\n      "name": "my-connector",\n      "config": {\n          "connector.class": "io.debezium.connector.postgresql.PostgresConnector",\n          "database.hostname": "[POSTGRES HOST NAME]",\n          "database.port": "[POSTGRES PORT]",\n          "database.user": "[DEBEZIUM USERNAME]",\n          "database.password": "[DEBEZIUM PASSWORD]",\n          "database.dbname": "[DATABASE NAME]",\n          "table.include.list": "[TABLE LIST]",\n          "topic.prefix": "[KAFKA TOPIC PREFIX]",\n          "key.converter": "io.confluent.connect.avro.AvroConverter",\n          "value.converter": "io.confluent.connect.avro.AvroConverter",\n          "key.converter.schemas.enable": "true",\n        \xa0 "value.converter.schemas.enable": "true",\n        \xa0 "key.converter.schema.registry.url": [SCHEMA REGISTRY URL],\n          "value.converter.schema.registry.url": [SCHEMA REGISTRY URL]\n      }\n  }\'\n'})}),"\n",(0,a.jsx)(n.p,{children:"Create a Debezium connector to read changes from a MySQL database into JSON-encoded Kafka topics:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'curl -i -X \\\n    POST -H "Accept:application/json" -H "Content-Type:application/json" \\\n    [KAFKA CONNECT HOSTNAME:PORT]/connectors/ -d \\\n    \'{ "name": "my-connector",\n        "config": {\n            "connector.class": "io.debezium.connector.mysql.MySqlConnector",\n            "tasks.max": "1",\n            "database.hostname": "[MYSQL HOST NAME]",\n            "database.port": "[MYSQL PORT]",\n            "database.user": "[DEBEZIUM USERNAME]",\n            "database.password": "[DEBEZIUM PASSWORD]",\n            "database.server.id": "[UNIQUE DATABASE SERVER ID]",\n            "database.server.name": "[UNIQUE DATABASE SERVER NAME]",\n            "database.include.list": "[DATABASES TO CONNECT]",\n            "database.history.kafka.bootstrap.servers": "[KAFKA HOSTNAME:PORT]",\n            "topic.prefix": "[DATABASE SERVER NAME]",\n            "schema.history.internal.kafka.topic": "schema-changes.[DATABASE SERVER NAME].internal",\n            "schema.history.internal.kafka.bootstrap.servers": "[KAFKA HOSTNAME:PORT]",\n            "include.schema.changes": "true",\n            "decimal.handling.mode": "string",\n        }\n    }\'\n'})}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["It is possible to externalize secrets in Kafka Connect connectors\nusing a Kafka ",(0,a.jsx)(n.code,{children:"ConfigProvider"})," implementation such as ",(0,a.jsx)(n.code,{children:"FileConfigProvider"}),"."]})}),"\n",(0,a.jsx)(n.h2,{id:"step-3-create-feldera-input-connector",children:"Step 3: Create Feldera input connector"}),"\n",(0,a.jsxs)(n.p,{children:["Configure an input connector for each Feldera SQL table that must ingest changes from Debezium.\nUse the ",(0,a.jsx)(n.code,{children:"kafka_input"})," transport with either ",(0,a.jsx)(n.code,{children:"json"})," or ",(0,a.jsx)(n.code,{children:"avro"})," format. Debezium automatically\ncreates a Kafka topic for each database table."]}),"\n",(0,a.jsxs)(n.p,{children:["Because input from Debezium uses the ",(0,a.jsx)(n.a,{href:"kafka",children:"Kafka input adapter"}),", it\nsupports ",(0,a.jsx)(n.a,{href:"/pipelines/fault-tolerance",children:"fault tolerance"})," too."]}),"\n",(0,a.jsx)(n.h3,{id:"json",children:"JSON"}),"\n",(0,a.jsx)(n.p,{children:"When using JSON encoding, make sure to set the following connector properties:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:'"update_format": "debezium"'})}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:'"json_flavor"'})," depending on the database:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For MySQL and MariaDB, set ",(0,a.jsx)(n.code,{children:'"json_flavor": "debezium_mysql"'})]}),"\n",(0,a.jsxs)(n.li,{children:["For all other databases set ",(0,a.jsx)(n.code,{children:'"json_flavor": "debezium_postgres"'})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Configure a Feldera connector to ingest changes from a Postgres DB via a JSON-encoded Kafka topics:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE my_table (\n  example_field: INT\n) WITH (\n  \'connectors\' = \'[{\n      "transport": {\n          "name": "kafka_input",\n          "config": {\n              "topic": "my_topic",\n              "start_from": "earliest",\n              "bootstrap.servers": "127.0.0.1:9092"\n          }\n      },\n      "format": {\n          "name": "json",\n          "config": {\n              "update_format": "debezium",\n              "json_flavor": "debezium_postgres"\n          }\n      }\n  }]\'\n)\n'})}),"\n",(0,a.jsx)(n.p,{children:"Configure a Feldera connector to ingest changes from a Postgres DB via a JSON-encoded Kafka topics:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE my_table (\n  example_field: INT\n) WITH (\n  \'connectors\' = \'[{\n      "transport": {\n          "name": "kafka_input",\n          "config": {\n              "topic": "my_topic",\n              "start_from": "earliest",\n              "bootstrap.servers": "127.0.0.1:9092"\n          }\n      },\n      "format": {\n          "name": "json",\n          "config": {\n              "update_format": "debezium",\n              "json_flavor": "debezium_mysql"\n          }\n      }\n  }]\'\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"avro",children:"Avro"}),"\n",(0,a.jsx)(n.p,{children:"Configure a Feldera connector to ingest changes from an Avro-encoded Kafka topic.\nMake sure to specify the URL of the schema registry to retrieve the Avro schema\nfor decoding the messages as part of Avro format configuration."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE my_table (\n    id INT NOT NULL PRIMARY KEY,\n    ts TIMESTAMP\n) with (\n  \'connectors\' = \'[{\n    "transport": {\n      "name": "kafka_input",\n      "config": {\n        "topic": "my_topic",\n        "start_from": "earliest",\n        "bootstrap.servers": "127.0.0.1:9092"\n      }\n    },\n    "format": {\n      "name": "avro",\n      "config": {\n        "registry_urls": ["http://127.0.0.1:8081"],\n        "update_format": "debezium"\n      }\n    }\n}]\');\n'})}),"\n",(0,a.jsx)(n.h2,{id:"table-schema-mapping",children:"Table schema mapping"}),"\n",(0,a.jsx)(n.p,{children:"In order to successfully ingest data change events from Debezium into a Feldera table, the schemas of the\nsource database table and the destination Feldera table must match, i.e., they should consist of the same\ncolumns with the same types, with the following exceptions:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["The Feldera table can contain additional ",(0,a.jsx)(n.strong,{children:"nullable"})," columns missing in the source table.  Such columns will be\nset to NULL during ingestion."]}),"\n",(0,a.jsx)(n.li,{children:"The source table can contain fields missing in the Feldera table.  Feldera will ignore such fields during ingestion."}),"\n",(0,a.jsx)(n.li,{children:"If the source table column is declared as non-nullable, the corresponding Feldera column can be nullable or non-nullable.\n(the inverse is not true: a nullable column cannot be synced into a non-nullable column)."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"json-columns",children:"JSON columns"}),"\n",(0,a.jsxs)(n.p,{children:["Source database columns of type ",(0,a.jsx)(n.code,{children:"JSON"})," and ",(0,a.jsx)(n.code,{children:"JSONB"})," can be mapped to Feldera columns of\neither ",(0,a.jsx)(n.a,{href:"/sql/json",children:(0,a.jsx)(n.code,{children:"VARIANT"})})," or ",(0,a.jsx)(n.code,{children:"VARCHAR"})," type.  The former allows efficient manipulation\nof JSON values, similar to the ",(0,a.jsx)(n.code,{children:"JSONB"})," type. The latter is preferable when working with JSON\nvalues as regular strings, when you don't need to parse or manipulate the JSON contents of the\nstring."]}),"\n",(0,a.jsx)(n.h2,{id:"additional-resources",children:"Additional resources"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["For more details on JSON support in Feldera, please refer to the ",(0,a.jsx)(n.a,{href:"/formats/json",children:"JSON Format Documentation"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["For more details on Avro support in Feldera, please refer to the ",(0,a.jsx)(n.a,{href:"/formats/avro",children:"Avro Format Documentation"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["For more information on configuring Kafka transport, visit the ",(0,a.jsx)(n.a,{href:"/connectors/sources/kafka",children:"Kafka Source Connector Documentation"}),"."]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>i});var t=o(96540);const a={},r=t.createContext(a);function s(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);