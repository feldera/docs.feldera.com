"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[355],{17884:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"formats/raw","title":"Raw Format","description":"This page describes configuration options specific to the raw data format.","source":"@site/docs/formats/raw.md","sourceDirName":"formats","slug":"/formats/raw","permalink":"/formats/raw","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"CSV Format","permalink":"/formats/csv"},"next":{"title":"Reference: Pipeline Lifecycle","permalink":"/pipelines/lifecycle"}}');var r=a(74848),s=a(28453);const o={},i="Raw Format",l={},c=[{value:"Configuring raw input connector",id:"configuring-raw-input-connector",level:2},{value:"Example 1: Ingest raw data from URL",id:"example-1-ingest-raw-data-from-url",level:3},{value:"Example 2: Ingest Kafka payload and metadata.",id:"example-2-ingest-kafka-payload-and-metadata",level:3},{value:"Ingesting raw data via HTTP",id:"ingesting-raw-data-via-http",level:2},{value:"Example",id:"example",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"raw-format",children:"Raw Format"})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["This page describes configuration options specific to the raw data format.\nSee ",(0,r.jsx)(n.a,{href:"/connectors/",children:"top-level connector documentation"})," for general information\nabout configuring input and output connectors."]})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"raw"})," data format can be used to configure an input connector to pass\nraw, unparsed, data buffers from the ",(0,r.jsx)(n.a,{href:"/connectors/sources",children:"transport connector"})," to the SQL program.\nNormally the byte stream received from the transport connector is parsed using the specified data ",(0,r.jsx)(n.a,{href:"/formats",children:"format"}),",\ne.g., ",(0,r.jsx)(n.a,{href:"/formats/json",children:"JSON"})," or ",(0,r.jsx)(n.a,{href:"/formats/avro",children:"Avro"}),". The parser converts the raw byte stream into a stream\nof SQL table records.  In some cases it is preferable to pass the raw bytes to the SQL program unmodified and\nperform all parsing in SQL. In particular this is useful for:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Custom data formats:"})," If the required data format is not supported by built-in parsers, raw data can be\ningested into a SQL table and decoded using a ",(0,r.jsx)(n.a,{href:"/sql/udf",children:"UDF"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Parallelized parsing"}),": Parsing large volumes of incoming data can become a performance bottleneck.\nNormally parsing is performed by the input connector outside of the SQL runtime.\nMoving parsing into the SQL program enables it to leverage the parallelism in the Feldera\nSQL runtime."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The raw format is currently only supported for input connectors."}),"\n",(0,r.jsx)(n.p,{children:"Note that the raw format supports only inserting records into the table and does not support deletions.\nThis limitation exists because the raw data stream lacks the metadata to differentiate between inserts and deletes."}),"\n",(0,r.jsx)(n.h2,{id:"configuring-raw-input-connector",children:"Configuring raw input connector"}),"\n",(0,r.jsx)(n.p,{children:"In order to ingest raw data:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Declare a table with a column of type ",(0,r.jsx)(n.code,{children:"VARBINARY [NOT NUL]"})," or ",(0,r.jsx)(n.code,{children:"VARCHAR [NOT NULL]"}),".  In the latter case, the connector\nwill parse input data as a UTF-8 string and will fail to parse chunks that are not valid UTF-8.\nThe table can contain additional columns, but all other columns in the table must be either nullable or\nhave default values."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Configure an input connector with the format name ",(0,r.jsx)(n.code,{children:"raw"}),".  The connector currently supports the following configuration\noptions:"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Property"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"mode"})}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:'"blob"'})," or ",(0,r.jsx)(n.code,{children:'"lines"'})]}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:'"blob"'})}),(0,r.jsxs)(n.td,{children:["Ingestion mode:",(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:[(0,r.jsx)(n.code,{children:"blob"})," (default) - ingest the entire data chunk received from the transport connector as a single SQL row. For message-oriented transports, such as Kafka or Pub/Sub, an input chunk corresponds to a message. For file-based transports, e.g., the ",(0,r.jsx)(n.a,{href:"/connectors/sources/http-get",children:"URL"})," connector or the ",(0,r.jsx)(n.a,{href:"/connectors/sources/s3",children:"S3"})," connector, a chunk represents an entire file or object."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)(n.code,{children:"lines"})," - split the input byte stream on the new line character (",(0,r.jsx)(n.code,{children:"\\n"}),") and ingest each line as a separate SQL row."]})]})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"column_name"})}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"Table column that will store the raw value. This setting is required if the table has more than 1 column."})]})]})]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["When using the ",(0,r.jsx)(n.code,{children:"blob"})," mode with a file-oriented transport connector such as S3, the entire file or object is ingested\nas a single record.  This can require a lot of memory when reading large files."]})}),"\n",(0,r.jsx)(n.h3,{id:"example-1-ingest-raw-data-from-url",children:"Example 1: Ingest raw data from URL"}),"\n",(0,r.jsx)(n.p,{children:"The following example shows a table with an input connector configured to ingest raw data from a URL line-by-line."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'create table raw_table(\n    data varchar\n) with (\n    \'connectors\' = \'[{\n        "format": {\n            "name": "raw",\n            "config": {\n                "mode": "lines"\n            }\n        },\n        "transport": {\n            "name": "url_input",\n            "config": {\n                "path": "https://feldera-basics-tutorial.s3.amazonaws.com/part.json"\n            }\n        }\n    }]\'\n);\n'})}),"\n",(0,r.jsx)(n.h3,{id:"example-2-ingest-kafka-payload-and-metadata",children:"Example 2: Ingest Kafka payload and metadata."}),"\n",(0,r.jsxs)(n.p,{children:["This example ingests Kafka message values as raw strings into the ",(0,r.jsx)(n.code,{children:"data"})," column, and Kafka\nmessage metadata into other columns (see ",(0,r.jsx)(n.a,{href:"/connectors/sources/kafka#metadata",children:"Accessing Kafka metadata"}),")."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE raw_table (\n    data VARCHAR,\n    kafka_headers MAP<STRING, VARBINARY> DEFAULT CAST(CONNECTOR_METADATA()[\'kafka_headers\'] as MAP<STRING, VARBINARY>),\n    kafka_timestamp TIMESTAMP DEFAULT CAST(CONNECTOR_METADATA()[\'kafka_timestamp\'] as TIMESTAMP),\n    kafka_topic VARCHAR DEFAULT CAST(CONNECTOR_METADATA()[\'kafka_topic\'] AS VARCHAR),\n    kafka_offset BIGINT DEFAULT CAST(CONNECTOR_METADATA()[\'kafka_offset\'] AS BIGINT),\n    kafka_partition INT DEFAULT CAST(CONNECTOR_METADATA()[\'kafka_partition\'] AS INT)\n) WITH (\n  \'materialized\' = \'true\',\n  \'connectors\' = \'[\n    {\n      "name": "raw_data",\n      "transport": {\n          "name": "kafka_input",\n          "config": {\n              "topic": "my_topic",\n              "start_from": "earliest",\n              "bootstrap.servers": "localhost:19092",\n              "include_headers": true,\n              "include_topic": true,\n              "include_offset": true,\n              "include_partition": true,\n              "include_timestamp": true\n          }\n      },\n      "format": {\n          "name": "raw",\n          "config": {\n              "column_name": "data"\n          }\n      }\n  }]\'\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"ingesting-raw-data-via-http",children:"Ingesting raw data via HTTP"}),"\n",(0,r.jsxs)(n.p,{children:["You can also push raw data to a pipeline via ",(0,r.jsx)(n.a,{href:"/connectors/sources/http",children:"HTTP"})," by specifying\n",(0,r.jsx)(n.code,{children:"format=json"})," and, optionally, ",(0,r.jsx)(n.code,{children:"mode=lines"})," in the request URL:"]}),"\n",(0,r.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,r.jsxs)(n.p,{children:["Create a pipeline called ",(0,r.jsx)(n.code,{children:"my_pipeline"})," with the following table declaration:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"create table raw_table(\n    data varchar\n);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Insert two records with values ",(0,r.jsx)(n.code,{children:"hello"})," and ",(0,r.jsx)(n.code,{children:"world"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"curl -i -X 'POST' \\\n  http://127.0.0.1:8080/v0/pipelines/my_pipeline/ingress/raw_table?format=raw&mode=lines \\\n  -d 'hello\n  world'\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>i});var t=a(96540);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);