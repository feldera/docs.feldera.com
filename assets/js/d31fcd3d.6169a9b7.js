"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[6293],{28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var s=n(96540);const a={},r=s.createContext(a);function i(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(r.Provider,{value:t},e.children)}},47479:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"use_cases/batch/intro","title":"Accelerating Batch Analytics with Feldera","description":"Introduction","source":"@site/docs/use_cases/batch/intro.md","sourceDirName":"use_cases/batch","slug":"/use_cases/batch/intro","permalink":"/use_cases/batch/intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Part 4: Random Data Generation","permalink":"/tutorials/basics/part4"},"next":{"title":"Part 1: Create a Spark SQL batch job","permalink":"/use_cases/batch/part1"}}');var a=n(74848),r=n(28453);const i={},o="Accelerating Batch Analytics with Feldera",c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"How it works",id:"how-it-works",level:2},{value:"This guide",id:"this-guide",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{LiteYouTubeEmbed:s}=t;return s||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("LiteYouTubeEmbed",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"accelerating-batch-analytics-with-feldera",children:"Accelerating Batch Analytics with Feldera"})}),"\n",(0,a.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(t.p,{children:["In modern data analytics, much of the heavy lifting is done by periodic ",(0,a.jsx)(t.strong,{children:"batch\njobs"})," that process large volumes of historical data and generate summary tables\nthat power interactive queries, reports, and dashboards."]}),"\n",(0,a.jsx)(t.p,{children:"However, as data changes over time, previously computed summaries become stale\nand must be updated by periodically re-running the batch job. This traditional\napproach has two major drawbacks:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Poor data freshness:"}),"  Batch analytics struggles to deliver up-to-date\nresults, often forcing users to wait hours or even days for refreshed\ninsights."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"High cost:"})," Each batch job reprocesses the entire dataset from scratch on\nevery run. As data volume grows, batch processing becomes increasingly\nexpensive."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Feldera replaces traditional batch jobs with ",(0,a.jsx)(t.strong,{children:"always-on"}),", incremental\npipelines that continuously update their outputs in real-time as new data\narrives."]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Watch the Webinar accompanying this series on Youtube:"}),"\n"]}),"\n",(0,a.jsx)(s,{id:"rcq3vqcSLeY"}),"\n",(0,a.jsx)(t.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Initial backfill."})," On startup, Feldera ingests historical data from a\ndatabase or data lake, and computes the initial output views.  This step\nresembles a traditional batch job, as it processes the entire dataset in one go."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Incremental updates."})," After backfill, Feldera continuously consumes new\nchanges from database tables or real-time sources (e.g., Kafka) and updates\noutput views incrementally."]}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"this-guide",children:"This guide"}),"\n",(0,a.jsx)(t.p,{children:"This guide provides a set of recipes to convert your batch pipelines into\nincremental Feldera pipelines:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/use_cases/batch/part1/",children:"Part 1: Create a simple Spark SQL batch job"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/use_cases/batch/part2/",children:"Part 2: Convert the Spark SQL job into a Feldera pipeline"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/use_cases/batch/part3/",children:"Part 3: Input connector orchestration: ingest historical and real-time data\nfrom multiple sources"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/use_cases/batch/part4/",children:"Part 4: Send outputs of the pipeline to multiple destinations"}),"."]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"By the end of the tutorial we will build the pipeline shown below:"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Data Flow Architecture",src:n(49895).A+"",width:"1678",height:"610"})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},49895:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/main-arch-63811ce4e5209da3838cf60243fcd81e.png"}}]);