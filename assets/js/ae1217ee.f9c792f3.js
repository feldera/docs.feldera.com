"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[5186],{28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var s=t(96540);const o={},r=s.createContext(o);function i(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(r.Provider,{value:n},e.children)}},84314:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"connectors/index","title":"Connectors: connect to data sources and sinks","description":"A Feldera pipeline can process data from multiple heterogeneous sources and","source":"@site/docs/connectors/index.mdx","sourceDirName":"connectors","slug":"/connectors/","permalink":"/connectors/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"User-Defined Functions","permalink":"/sql/udf"},"next":{"title":"Uniqueness Constraints","permalink":"/connectors/unique_keys"}}');var o=t(74848),r=t(28453);const i={},c="Connectors: connect to data sources and sinks",a={},l=[{value:"Basics",id:"basics",level:2},{value:"Generic attributes",id:"generic-attributes",level:2},{value:"Configuring the output buffer",id:"configuring-the-output-buffer",level:3},{value:"Additional resources",id:"additional-resources",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"connectors-connect-to-data-sources-and-sinks",children:"Connectors: connect to data sources and sinks"})}),"\n",(0,o.jsxs)(n.p,{children:["A Feldera pipeline can process data from multiple heterogeneous sources and\nproduce outputs to multiple heterogeneous destinations. To this end it relies\non a growing library of ",(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"sources",children:"input"})})," and ",(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"sinks",children:"output"})})," connectors."]}),"\n",(0,o.jsx)(n.h2,{id:"basics",children:"Basics"}),"\n",(0,o.jsxs)(n.p,{children:["Users configure connectors using a JSON object, that describes an external source or sink such as a database\ntable or a Kafka topic. A SQL table can have multiple source connectors attached to it, specified as a\nlist of JSON connector objects under the ",(0,o.jsx)(n.code,{children:"'connectors'"})," attribute in the ",(0,o.jsx)(n.code,{children:"WITH"})," clause of the table.\nSimilarly, a views can have multiple sink connectors attached to it."]}),"\n",(0,o.jsxs)(n.p,{children:["Here is an example, where the ",(0,o.jsx)(n.code,{children:"VENDOR"})," table has one connector, configured to fetch and insert JSON data\nfrom an HTTP URL, and a ",(0,o.jsx)(n.code,{children:"VENDOR_VIEW"})," which sends the changes of the view\nto a Kafka topic in a format that can be consumed by Debezium:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:'create table VENDOR (\n    id bigint not null primary key,\n    name varchar,\n    address varchar\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/vendor.json"}\n    },\n    "format": { "name": "json" }\n}]\');\n\ncreate view VENDOR_VIEW\nWITH (\n    \'connectors\' = \'[{\n        "max_queued_records": 1000,\n        "format": {\n            "name": "json",\n            "config": {\n                "update_format": "debezium"\n            }\n        },\n        "transport": {\n            "name": "kafka_output",\n            "config": {\n                "bootstrap.servers": "redpanda:9092",\n                "topic": "test_view"\n            }\n        }\n    }]\'\n)\nas select * from VENDOR;\n'})}),"\n",(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"WITH"})," clause for tables needs to be put at the end, after the column definitions, whereas for views it has to\nappear before the ",(0,o.jsx)(n.code,{children:"AS"})," clause to resolve any parsing ambiguities."]})}),"\n",(0,o.jsx)(n.p,{children:"A connector specification consists of three parts:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"#generic-attributes",children:"Generic attributes"})," common to all connectors, such as backpressure thresholds."]}),"\n",(0,o.jsxs)(n.li,{children:["Transport specification (",(0,o.jsx)(n.code,{children:"transport"}),") for either ",(0,o.jsx)(n.a,{href:"/connectors/sources/",children:"input"})," or ",(0,o.jsx)(n.a,{href:"/connectors/sinks/",children:"output"}),"\ndefines the data transport to be used by the connector.\nExample transports include ",(0,o.jsx)(n.a,{href:"/connectors/sources/kafka",children:"Kafka"}),",\n",(0,o.jsx)(n.a,{href:"/connectors/sources/http-get",children:"URL"}),", ",(0,o.jsx)(n.a,{href:"/connectors/sources/delta",children:"Delta Lake"}),", etc."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/formats",children:"Data format specification"})," (",(0,o.jsx)(n.code,{children:"format"}),"), which defines the data format for the connector.\nExample data formats include ",(0,o.jsx)(n.a,{href:"/formats/csv",children:"CSV"}),", ",(0,o.jsx)(n.a,{href:"/formats/json",children:"JSON"}),", ",(0,o.jsx)(n.a,{href:"/formats/parquet",children:"Parquet"}),", or\nAvro."]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["Some transports, e.g., ",(0,o.jsx)(n.a,{href:"/connectors/sinks/delta",children:"Delta Lake"})," and\n",(0,o.jsx)(n.a,{href:"/connectors/sources/datagen",children:"datagen"}),", use fixed predefined data formats and do not require the\nformat section in the connector specification."]})}),"\n",(0,o.jsx)(n.p,{children:"This architecture allows the user to combine different transports and data formats."}),"\n",(0,o.jsxs)(n.p,{children:["These basics apply to all connectors ",(0,o.jsx)(n.strong,{children:"except"})," the HTTP ",(0,o.jsx)(n.a,{href:"/connectors/sources/http",children:"input"})," and\n",(0,o.jsx)(n.a,{href:"/connectors/sinks/http",children:"output"})," connectors which are not managed by the user, as they directly feed/fetch data\ninto/from a pipeline via dedicated pipeline endpoints and therefore do not need to be configured in the ",(0,o.jsx)(n.code,{children:"WITH"})," clauses\nof tables and views."]}),"\n",(0,o.jsx)(n.h2,{id:"generic-attributes",children:"Generic attributes"}),"\n",(0,o.jsx)(n.p,{children:"The following attributes are common to all connectors:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"name"})," - The name that is given to the connector, which must be\nunique among the connectors of the table or view. This is particularly\nuseful to define when wanting to refer to it, for example to\n",(0,o.jsx)(n.a,{href:"/connectors/orchestration",children:"start or pause it at runtime"}),".\nBy default, this is randomly generated."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"paused"})," - If set to to true the connector will not fetch or push data to the pipeline when started\nunless ",(0,o.jsx)(n.a,{href:"/api/start-resume-or-pause-the-input-connector",children:"explicitly enabled through the API"}),".\nBy default this is set to false."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"labels"})," - An optional list of text labels associated with the connector.\nThis property is used in conjunction with the ",(0,o.jsx)(n.code,{children:"start_after"})," property\nto implement ",(0,o.jsx)(n.a,{href:"/connectors/orchestration#automatic-connector-orchestration",children:"automatic connector orchestration"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"start_after"})," - Specifies one or more labels. When this property is set, the connector is created\nin the Paused state and is automatically activated once all connectors tagged with at least one\nof the specified labels have finished ingesting data.  This property is used in conjunction with the ",(0,o.jsx)(n.code,{children:"labels"})," property\nto implement ",(0,o.jsx)(n.a,{href:"/connectors/orchestration#automatic-connector-orchestration",children:"automatic connector orchestration"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"max_queued_records"})," - The approximate maximum number of records to\nkeep in memory.  For an input connector, this is the maximum number\nthat the endpoint will read into memory, before the endpoint pauses\nfurther reading until the pipeline has consumed some of the backlog.\nFor an output connector, this is the maximum number that the\nendpoint will hold in memory waiting for the output endpoint to send\nthem, before the circuit pauses execution until the backlog\nsubsides.  By default, this is 1,000,000."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"max_batch_size"})," - For an input connector, the approximate maximum\nnumber of records that the pipeline will process in a single\npipeline step.  By default, this is 10,000."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"index"})," \u2013 ",(0,o.jsx)(n.em,{children:"(Output connectors only)"})," The name of an index created by a SQL\nCREATE INDEX statement that defines\nthe unique key for the view. This allows the connector to combine related\ninsert and delete events into a single atomic update.\nSee ",(0,o.jsx)(n.a,{href:"/connectors/unique_keys",children:"Uniqueness Constraints"}),"."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"configuring-the-output-buffer",children:"Configuring the output buffer"}),"\n",(0,o.jsxs)(n.p,{children:["By default a Feldera pipeline sends a batch of changes to the output transport\nfor each batch of input updates it processes.  This can result in a stream of\nsmall updates, which is normal and even preferable for output transports like\n",(0,o.jsx)(n.a,{href:"/connectors/sinks/kafka",children:"Kafka"}),"; however it can cause performance problems\nfor other connectors, such as the ",(0,o.jsx)(n.a,{href:"/connectors/sinks/delta",children:"Delta Lake connector"}),"\nby creating a large number of small files."]}),"\n",(0,o.jsx)(n.p,{children:"The output buffer mechanism is designed to solve this problem by decoupling the\nrate at which the pipeline pushes changes to the output transport from the rate\nof input changes.  It works by accumulating updates inside the pipeline\nfor up to a user-defined period of time or until accumulating a user-defined number\nof updates and writing them as a single batch to the output transport."}),"\n",(0,o.jsx)(n.p,{children:"The output buffer can be setup for each individual output connector as part\nof connector configuration.  The following parameters are used to configure the\noutput buffer:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"enable_output_buffer"})," - Enable output buffer."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"max_output_buffer_time_millis"})," - Maximum time in milliseconds data is kept\nin the output buffer."]}),"\n",(0,o.jsxs)(n.p,{children:["When not specified, data is kept in the buffer indefinitely until one of\nthe other trigger conditions is satisfied.  When this option is\nset the buffer will be flushed at most every\n",(0,o.jsx)(n.code,{children:"max_output_buffer_time_millis"})," milliseconds."]}),"\n",(0,o.jsxs)(n.p,{children:["This configuration option requires the ",(0,o.jsx)(n.code,{children:"enable_output_buffer"})," flag\nto be set."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"max_output_buffer_size_records"})," - Maximum number of updates to be kept in\nthe output buffer."]}),"\n",(0,o.jsx)(n.p,{children:"This parameter bounds the maximal size of the buffer.\nNote that the size of the buffer is not always equal to the\ntotal number of updates output by the pipeline. Updates to the\nsame record can overwrite or cancel previous updates."}),"\n",(0,o.jsx)(n.p,{children:"When not specified, the buffer can grow indefinitely until one of\nthe other trigger conditions is satisfied."}),"\n",(0,o.jsxs)(n.p,{children:["This configuration option requires the ",(0,o.jsx)(n.code,{children:"enable_output_buffer"})," flag\nto be set."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["When the ",(0,o.jsx)(n.code,{children:"enable_output_buffer"})," flag is set, at least one of\n",(0,o.jsx)(n.code,{children:"max_output_buffer_time_millis"})," or ",(0,o.jsx)(n.code,{children:"max_output_buffer_size_records"})," must be\nspecified."]})}),"\n",(0,o.jsxs)(n.p,{children:["See ",(0,o.jsx)(n.a,{href:"/connectors/sinks/delta",children:"Delta Lake output connector documentation"}),"\nfor an example of configuring the output buffer."]}),"\n",(0,o.jsx)(n.h2,{id:"additional-resources",children:"Additional resources"}),"\n",(0,o.jsx)(n.p,{children:"For more information, see:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/tutorials/basics/part3",children:"Tutorial on using input and output connectors"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/tutorials/basics/part2",children:"Tutorial on using HTTP-based input and output"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/unique_keys",children:"Tables and views with uniqueness constraints"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/orchestration",children:"Input connector orchestration"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/completion-tokens",children:"Synchronous processing with completion tokens"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/secret-references",children:"Configuring connectors with secrets"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/sources",children:"Supported source transports"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/connectors/sinks",children:"Supported sinks transports"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"pathname:///python/examples.html#end-to-end-example-with-kafka-sink",children:"End to end example with Kafka using Feldera Python SDK"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);