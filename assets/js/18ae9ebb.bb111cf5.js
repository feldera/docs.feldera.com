"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[7068],{15779:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"tutorials/basics/part3","title":"Part 3: Input and Output Connectors","description":"In this part of the tutorial where we will","source":"@site/docs/tutorials/basics/part3.md","sourceDirName":"tutorials/basics","slug":"/tutorials/basics/part3","permalink":"/tutorials/basics/part3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Part 2: HTTP-based Input and Output","permalink":"/tutorials/basics/part2"},"next":{"title":"Part 4: Random Data Generation","permalink":"/tutorials/basics/part4"}}');var r=t(74848),o=t(28453);const s={},i="Part 3: Input and Output Connectors",c={},l=[{value:"Computing on data in motion",id:"computing-on-data-in-motion",level:2},{value:"Step 1. Configure HTTPS GET connectors",id:"step-1-configure-https-get-connectors",level:2},{value:"Step 2. Configure Kafka/Redpanda connectors",id:"step-2-configure-kafkaredpanda-connectors",level:2},{value:"Install Redpanda",id:"install-redpanda",level:3},{value:"Create input/output topics",id:"create-inputoutput-topics",level:3},{value:"Configure connectors",id:"configure-connectors",level:3},{value:"Run the pipeline",id:"run-the-pipeline",level:3},{value:"Takeaways",id:"takeaways",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"part-3-input-and-output-connectors",children:"Part 3: Input and Output Connectors"})}),"\n",(0,r.jsx)(n.p,{children:"In this part of the tutorial where we will"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Learn to connect Feldera pipelines to external data sources and sinks."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Introduce the third key concept behind Feldera: ",(0,r.jsx)(n.em,{children:"computation over data in\nmotion"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"computing-on-data-in-motion",children:"Computing on data in motion"}),"\n",(0,r.jsx)(n.p,{children:"A Feldera pipeline starts evaluating queries as soon as it receives\nthe first input record and continues updating the results incrementally as more\ninputs arrive.  This enables Feldera to operate over data en-route from a source\nto a destination.  The destination, be it a database, a data lake, an ML model,\nor a real-time dashboard, receives the latest query results, and not the raw\ndata.  A Feldera pipeline can connect multiple heterogeneous sources\nto multiple destinations.  In this part of the tutorial, we will build such a\npipeline:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Real-time supply chain analytics",src:t(83254).A+"",width:"1096",height:"520"})}),"\n",(0,r.jsx)(n.h2,{id:"step-1-configure-https-get-connectors",children:"Step 1. Configure HTTPS GET connectors"}),"\n",(0,r.jsx)(n.p,{children:"An HTTPS GET connector retrieves data from a user-provided URL and pushes it to a\nSQL table.  Let us start with adding some GET connectors to the pipeline we\ncreated in Part 1 of this tutorial.  We uploaded minimal datasets for the three\ntables in this example to a public S3 bucket:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://feldera-basics-tutorial.s3.amazonaws.com/part.json",children:"https://feldera-basics-tutorial.s3.amazonaws.com/part.json"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://feldera-basics-tutorial.s3.amazonaws.com/vendor.json",children:"https://feldera-basics-tutorial.s3.amazonaws.com/vendor.json"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://feldera-basics-tutorial.s3.amazonaws.com/price.json",children:"https://feldera-basics-tutorial.s3.amazonaws.com/price.json"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Modify your SQL table declarations adding the ",(0,r.jsx)(n.code,{children:"WITH"})," clause with input connector configuration:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'create table VENDOR (\n    id bigint not null primary key,\n    name varchar,\n    address varchar\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/vendor.json"}\n    },\n    "format": { "name": "json" }\n}]\');\n\ncreate table PART (\n    id bigint not null primary key,\n    name varchar\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/part.json"  }\n    },\n    "format": { "name": "json" }\n}]\');\n\ncreate table PRICE (\n    part bigint not null,\n    vendor bigint not null,\n    price integer\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/price.json"  }\n    },\n    "format": { "name": "json" }\n}]\');\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Select the ",(0,r.jsx)(n.code,{children:"PREFERRED_VENDOR"})," view in the ",(0,r.jsx)(n.code,{children:"Change Stream"})," tab and start the pipeline.\nThe input connectors ingest data from S3 and push it to the pipeline.\nYou should see the outputs appear in the ",(0,r.jsx)(n.code,{children:"Change Stream"})," tab."]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["You must select the table or view you want to monitor in the ",(0,r.jsx)(n.code,{children:"Change Stream"})," tab ",(0,r.jsx)(n.em,{children:"before"})," starting the pipeline\nin order to observe all updates to the view from the start of the execution."]})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"Feldera will soon support browsing and querying the entire contents of a table or view."})}),"\n",(0,r.jsx)(n.h2,{id:"step-2-configure-kafkaredpanda-connectors",children:"Step 2. Configure Kafka/Redpanda connectors"}),"\n",(0,r.jsxs)(n.p,{children:["Next, we will add a pair of connectors to our pipeline to ingest changes to the ",(0,r.jsx)(n.code,{children:"PRICE"}),"\ntable from a Kafka topic and output changes to the ",(0,r.jsx)(n.code,{children:"PREFERRED_VENDOR"})," table to\nanother Kafka topic."]}),"\n",(0,r.jsx)(n.h3,{id:"install-redpanda",children:"Install Redpanda"}),"\n",(0,r.jsxs)(n.p,{children:["To complete this part of the tutorial, you will need access to a Kafka cluster.  For your\nconvenience, the Feldera Docker Compose file contains instructions to bring up a local\ninstance of Redpanda, a Kafka-compatible message queue.  If you started Feldera\nin the demo mode (by supplying the ",(0,r.jsx)(n.code,{children:"--profile demo"})," switch to ",(0,r.jsx)(n.code,{children:"docker compose"}),") then\nthe Redpanda container should already be running.  Otherwise, you can start it\nusing the following command:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"curl -L https://raw.githubusercontent.com/feldera/feldera/main/deploy/docker-compose.yml | docker compose -f - up redpanda\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Next, you will need to install ",(0,r.jsx)(n.code,{children:"rpk"}),", the Redpanda CLI, by following the instructions on\n",(0,r.jsx)(n.a,{href:"https://docs.redpanda.com/current/get-started/rpk-install/",children:"redpanda.com"}),".  On\nsuccess, you will be able to retrieve the state of the Redpanda cluster using:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rpk -X brokers=127.0.0.1:19092 cluster metadata\n"})}),"\n",(0,r.jsx)(n.h3,{id:"create-inputoutput-topics",children:"Create input/output topics"}),"\n",(0,r.jsxs)(n.p,{children:["Create a pair of Redpanda topics that will be used to send input updates\nto the ",(0,r.jsx)(n.code,{children:"PRICE"})," table and receive output changes from the ",(0,r.jsx)(n.code,{children:"PREFERRED_VENDOR"})," view."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rpk -X brokers=127.0.0.1:19092 topic create price preferred_vendor\n"})}),"\n",(0,r.jsx)(n.h3,{id:"configure-connectors",children:"Configure connectors"}),"\n",(0,r.jsxs)(n.p,{children:["Modify the ",(0,r.jsx)(n.code,{children:"PRICE"})," table adding a Kafka input connector to read from the ",(0,r.jsx)(n.code,{children:"price"})," topic:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'create table PRICE (\n    part bigint not null,\n    vendor bigint not null,\n    price integer\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/price.json"  }\n    },\n    "format": { "name": "json" }\n},\n{\n    "format": {"name": "json"},\n    "transport": {\n        "name": "kafka_input",\n        "config": {\n            "topic": "price",\n            "start_from": "earliest",\n            "bootstrap.servers": "redpanda:9092"\n        }\n    }\n}]\');\n'})}),"\n",(0,r.jsx)(n.p,{children:"This table now ingests data from two heterogeneous sources: an S3 bucket and a Kafka topic."}),"\n",(0,r.jsxs)(n.p,{children:["Add a Kafka connector to the ",(0,r.jsx)(n.code,{children:"PREFERRED_VENDOR"})," view:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'create view PREFERRED_VENDOR (\n    part_id,\n    part_name,\n    vendor_id,\n    vendor_name,\n    price\n)\nWITH (\n    \'connectors\' = \'[{\n        "format": {"name": "json"},\n        "transport": {\n            "name": "kafka_output",\n            "config": {\n                "topic": "preferred_vendor",\n                "bootstrap.servers": "redpanda:9092"\n            }\n        }\n    }]\'\n)\nas\n    select\n        PART.id as part_id,\n        PART.name as part_name,\n        VENDOR.id as vendor_id,\n        VENDOR.name as vendor_name,\n        PRICE.price\n    from\n        PRICE,\n        PART,\n        VENDOR,\n        LOW_PRICE\n    where\n        PRICE.price = LOW_PRICE.price AND\n        PRICE.part = LOW_PRICE.part AND\n        PART.id = PRICE.part AND\n        VENDOR.id = PRICE.vendor;\n'})}),"\n",(0,r.jsx)(n.p,{children:"Here is the final version of the program with all connector:"}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Click to expand SQL code"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'create table VENDOR (\n    id bigint not null primary key,\n    name varchar,\n    address varchar\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/vendor.json"}\n    },\n    "format": { "name": "json" }\n}]\');\n\ncreate table PART (\n    id bigint not null primary key,\n    name varchar\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/part.json"  }\n    },\n    "format": { "name": "json" }\n}]\');\n\ncreate table PRICE (\n    part bigint not null,\n    vendor bigint not null,\n    price integer\n) WITH (\'connectors\' = \'[{\n    "transport": {\n        "name": "url_input", "config": {"path": "https://feldera-basics-tutorial.s3.amazonaws.com/price.json"  }\n    },\n    "format": { "name": "json" }\n},\n{\n    "format": {"name": "json"},\n    "transport": {\n        "name": "kafka_input",\n        "config": {\n            "topic": "price",\n            "start_from": "earliest",\n            "bootstrap.servers": "redpanda:9092"\n        }\n    }\n}]\');\n\n-- Lowest available price for each part across all vendors.\ncreate view LOW_PRICE (\n    part,\n    price\n) as\n    select part, MIN(price) as price from PRICE group by part;\n\n-- Lowest available price for each part along with part and vendor details.\ncreate view PREFERRED_VENDOR (\n    part_id,\n    part_name,\n    vendor_id,\n    vendor_name,\n    price\n)\nWITH (\n    \'connectors\' = \'[{\n        "format": {"name": "json"},\n        "transport": {\n            "name": "kafka_output",\n            "config": {\n                "topic": "preferred_vendor",\n                "bootstrap.servers": "redpanda:9092"\n            }\n        }\n    }]\'\n)\nas\n    select\n        PART.id as part_id,\n        PART.name as part_name,\n        VENDOR.id as vendor_id,\n        VENDOR.name as vendor_name,\n        PRICE.price\n    from\n        PRICE,\n        PART,\n        VENDOR,\n        LOW_PRICE\n    where\n        PRICE.price = LOW_PRICE.price AND\n        PRICE.part = LOW_PRICE.part AND\n        PART.id = PRICE.part AND\n        VENDOR.id = PRICE.vendor;\n'})})]}),"\n",(0,r.jsx)(n.h3,{id:"run-the-pipeline",children:"Run the pipeline"}),"\n",(0,r.jsxs)(n.p,{children:["Start the pipeline.\nThe ",(0,r.jsx)(n.code,{children:"GET"})," connectors instantly ingest input files from S3 and the output\nRedpanda connector writes computed view updates to the output topic.  Use the\nRedpanda CLI to inspect the outputs:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rpk -X brokers=127.0.0.1:19092 topic consume preferred_vendor -f '%v'\n"})}),"\n",(0,r.jsx)(n.p,{children:"which should output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{"insert":{"PART_ID":1,"PART_NAME":"Flux Capacitor","VENDOR_ID":2,"VENDOR_NAME":"HyperDrive Innovations","PRICE":"10000"}}\n{"insert":{"PART_ID":2,"PART_NAME":"Warp Core","VENDOR_ID":1,"VENDOR_NAME":"Gravitech Dynamics","PRICE":"15000"}}\n{"insert":{"PART_ID":3,"PART_NAME":"Kyber Crystal","VENDOR_ID":3,"VENDOR_NAME":"DarkMatter Devices","PRICE":"9000"}}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["In a different terminal, push input updates to the ",(0,r.jsx)(n.code,{children:"price"})," topic using the JSON\nformat we are already familiar with from ",(0,r.jsx)(n.a,{href:"/tutorials/basics/part2",children:"Part2"})," of the tutorial:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'echo \'\n{"delete": {"part": 1, "vendor": 2, "price": 10000}}\n{"insert": {"part": 1, "vendor": 2, "price": 30000}}\n{"delete": {"part": 2, "vendor": 1, "price": 15000}}\n{"insert": {"part": 2, "vendor": 1, "price": 50000}}\n{"insert": {"part": 1, "vendor": 3, "price": 20000}}\n{"insert": {"part": 2, "vendor": 3, "price": 11000}}\' | rpk -X brokers=127.0.0.1:19092 topic produce price -f \'%v\'\n'})}),"\n",(0,r.jsxs)(n.p,{children:["You should see the following new output updates in the ",(0,r.jsx)(n.code,{children:"preferred_vendor"})," topic:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{"delete":{"PART_ID":1,"PART_NAME":"Flux Capacitor","VENDOR_ID":2,"VENDOR_NAME":"HyperDrive Innovations","PRICE":"10000"}}\n{"insert":{"PART_ID":1,"PART_NAME":"Flux Capacitor","VENDOR_ID":3,"VENDOR_NAME":"DarkMatter Devices","PRICE":"20000"}}\n{"delete":{"PART_ID":2,"PART_NAME":"Warp Core","VENDOR_ID":1,"VENDOR_NAME":"Gravitech Dynamics","PRICE":"15000"}}\n{"insert":{"PART_ID":2,"PART_NAME":"Warp Core","VENDOR_ID":3,"VENDOR_NAME":"DarkMatter Devices","PRICE":"11000"}}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"takeaways",children:"Takeaways"}),"\n",(0,r.jsx)(n.p,{children:"To summarize Part 3 of the tutorial,"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"A Feldera pipeline can ingest data from multiple sources and send outputs to\nmultiple destinations using input and output connectors."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Combined with the incremental query evaluation mechanism, this enables Feldera\nto analyze data on the fly as it moves from sources to destinations, so that\nthe destination receives up-to-date query results in real time."}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var a=t(96540);const r={},o=a.createContext(r);function s(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(o.Provider,{value:n},e.children)}},83254:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/supply-chain-analytics-32e775882a2ecd7d9cb95e4d0245efca.png"}}]);