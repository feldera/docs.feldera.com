"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[7166],{22782:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"tutorials/basics/part4","title":"Part 4: Random Data Generation","description":"This is the final part of the tutorial where we will","source":"@site/docs/tutorials/basics/part4.md","sourceDirName":"tutorials/basics","slug":"/tutorials/basics/part4","permalink":"/tutorials/basics/part4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Part 3: Input and Output Connectors","permalink":"/tutorials/basics/part3"},"next":{"title":"Accelerating Batch Analytics with Feldera","permalink":"/use_cases/batch/intro"}}');var a=t(74848),i=t(28453);const s={},o="Part 4: Random Data Generation",d={},c=[{value:"Why random data?",id:"why-random-data",level:2},{value:"Step 1. Create datagen connectors",id:"step-1-create-datagen-connectors",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"part-4-random-data-generation",children:"Part 4: Random Data Generation"})}),"\n",(0,a.jsx)(n.p,{children:"This is the final part of the tutorial where we will"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Learn to connect Feldera pipelines to a random row generator for testing,\nbenchmarking and debugging purposes."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Give a glimpse of the HTTP API to programmatically interact with Feldera."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"You can skip this part if you are working with pre-existing data sources."}),"\n",(0,a.jsx)(n.h2,{id:"why-random-data",children:"Why random data?"}),"\n",(0,a.jsx)(n.p,{children:"When creating a new pipeline, you might find yourself writing some SQL, without having\nany data to test it readily available. In this case, you can use the random data generator\nto create test data on the fly. This is especially useful when you want to test with\nlarge volumes of data."}),"\n",(0,a.jsx)(n.h2,{id:"step-1-create-datagen-connectors",children:"Step 1. Create datagen connectors"}),"\n",(0,a.jsx)(n.p,{children:"You already learned how to create connectors and connect them to your pipeline in the previous\nparts of the tutorial. The datagen connector is just another connector that generates random\nrows for a table with some constraints on what gets generated based on the configuration you provide."}),"\n",(0,a.jsxs)(n.p,{children:["Let's configure a datagen connector for the ",(0,a.jsx)(n.code,{children:"VENDOR"})," table to generate the following contents:"]}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"ID"}),(0,a.jsx)(n.th,{children:"NAME"}),(0,a.jsx)(n.th,{children:"ADDRESS"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"0"}),(0,a.jsx)(n.td,{children:"Gravitech Dynamics"}),(0,a.jsx)(n.td,{children:"222 Graviton Lane"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"1"}),(0,a.jsx)(n.td,{children:"HyperDrive Innovations"}),(0,a.jsx)(n.td,{children:"456 Warp Way"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"2"}),(0,a.jsx)(n.td,{children:"DarkMatter Devices"}),(0,a.jsx)(n.td,{children:"333 Singularity Street"})]})]})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'create table VENDOR (\n    id bigint not null primary key,\n    name varchar,\n    address varchar\n) with (\n  \'materialized\' = \'true\',\n  \'connectors\' = \'[{\n    "transport": {\n      "name": "datagen",\n      "config": {\n        "plan": [\n          { "limit": 3,\n            "fields": {\n              "name": { "values": ["Gravitech Dynamics", "HyperDrive Innovations", "DarkMatter Devices"] },\n              "address": { "values": ["222 Graviton Lane", "456 Warp Way", "333 Singularity Street"] } } }\n        ]\n      }\n    }\n  }]\'\n);\n'})}),"\n",(0,a.jsxs)(n.p,{children:["First, we specify ",(0,a.jsx)(n.code,{children:"datagen"})," as the transport. In the ",(0,a.jsx)(n.code,{children:"config"})," section, we define a ",(0,a.jsx)(n.code,{children:"plan"})," that describes how the\nrows are generated. You can add multiple plans to this list, and they will be executed sequentially, but for now we only need one."]}),"\n",(0,a.jsxs)(n.p,{children:["In the plan we set the ",(0,a.jsx)(n.code,{children:"limit"})," parameter, it specifies how many rows should be generated.\nIn ",(0,a.jsx)(n.code,{children:"fields"}),", we describe how the values for each column should be generated: For the ",(0,a.jsx)(n.code,{children:"name"})," and ",(0,a.jsx)(n.code,{children:"address"}),"\ncolumn, we give the list of the three names and addresses from the table above.\nWe don't need to configure anything for the ",(0,a.jsx)(n.code,{children:"id"})," column because the default strategy for generating integer values is to\ngenerate an incrementing sequence of numbers starting from 0."]}),"\n",(0,a.jsxs)(n.p,{children:['We\'ll cover these "increment" generation strategies in more detail for the next table, ',(0,a.jsx)(n.code,{children:"PART"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'create table PART (\n    id bigint not null primary key,\n    name varchar\n) WITH (\n  \'connectors\' = \'[{\n    "transport": {\n      "name": "datagen",\n      "config": {\n        "plan": [\n          { "limit": 3,\n            "fields": {\n              "id": { "strategy": "increment", "range": [1, 4] },\n              "name": { "strategy": "increment", "values": ["Flux Capacitor", "Warp Core", "Kyber Crystal"] } } }\n        ]\n      }\n    }\n  }]\'\n);\n'})}),"\n",(0,a.jsx)(n.p,{children:"This will fill the table with the following contents:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"ID"}),(0,a.jsx)(n.th,{children:"NAME"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"1"}),(0,a.jsx)(n.td,{children:"Flux Capacitor"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"2"}),(0,a.jsx)(n.td,{children:"Warp Core"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"3"}),(0,a.jsx)(n.td,{children:"Kyber Crystal"})]})]})]}),"\n",(0,a.jsxs)(n.p,{children:["Each member of the ",(0,a.jsx)(n.code,{children:"fields"})," section can set a ",(0,a.jsx)(n.code,{children:"strategy"})," that defines how the values are generated.\nThe ",(0,a.jsx)(n.code,{children:"increment"})," strategy is the default, so we could've omitted it like in the previous table.\nWhat's new is that we added the ",(0,a.jsx)(n.code,{children:"range"})," parameter for the ",(0,a.jsx)(n.code,{children:"id"})," column. That means we narrow the range of\nvalues generated for this field. Instead of starting from 0 as we did in the previous table,\nthe ",(0,a.jsx)(n.code,{children:"id"})," rows now have values ",(0,a.jsx)(n.code,{children:"1, 2, 3"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["For the ",(0,a.jsx)(n.code,{children:"name"})," column, we also use the ",(0,a.jsx)(n.code,{children:"increment"})," strategy. Again, we specify a fixed set of\n",(0,a.jsx)(n.code,{children:"values"}),". As previously, the ",(0,a.jsx)(n.code,{children:"increment"})," strategy will select the values from the list one-by-one."]}),"\n",(0,a.jsxs)(n.p,{children:["For the last table, ",(0,a.jsx)(n.code,{children:"PRICE"}),", we insert some static contents to the table as we did before, but then we add a second\nplan to the connector that dynamically updates the prices to make it more interesting."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'create table PRICE (\n  part bigint not null,\n  vendor bigint not null,\n  price integer,\n  -- Make sure that new updates overwrite existing entries in PRICE for the same part and vendor ids.\n  PRIMARY KEY (part, vendor)\n) with (\n  \'materialized\' = \'true\',\n  \'connectors\' = \'[\n  {\n    "transport": {\n      "name": "datagen",\n      "config": {\n        "plan": [\n          { "limit": 3,\n            "fields": {\n              "part": { "range": [1, 4] },\n              "vendor": { "values": [1, 0, 2] },\n              "price": { "values": [10000, 15000, 9000] } } },\n           { "rate": 1,\n             "fields": {\n              "vendor": { "values": [1, 0, 2] },\n              "part": { "strategy": "zipf", "range": [1, 4] },\n              "price": { "strategy": "uniform", "range": [9000, 15000] } }\n           }\n        ]\n      }\n    }\n  }\n  ]\'\n);\n'})}),"\n",(0,a.jsxs)(n.p,{children:["The first plan is similar to what we saw in the previous table (except we omit specifying the default increment\nstrategy). The second plan has some new settings. We add a ",(0,a.jsx)(n.code,{children:"rate: 1"})," to tell the connector to emit one record\nevery second, and we omit ",(0,a.jsx)(n.code,{children:"limit"})," so this plan will continuously generate records until the pipeline is stopped.\nWe keep the ",(0,a.jsx)(n.code,{children:"vendor"})," column fixed, so every time we emit a record it will affect a different vendor.\nNext we use a new strategy, a Zipf distribution for the ",(0,a.jsx)(n.code,{children:"part"})," column. This means that the connector will\ngenerate a random part ID, but the distribution of the IDs will be skewed towards the first ID in the range.\nFinally, we set the ",(0,a.jsx)(n.code,{children:"price"})," column to be generated with a ",(0,a.jsx)(n.code,{children:"uniform"})," strategy, and a ",(0,a.jsx)(n.code,{children:"range"}),", which means that the price\nwill be a random number between ",(0,a.jsx)(n.code,{children:"9000"})," and ",(0,a.jsx)(n.code,{children:"15000"}),"."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["The data generator currently only generates insertions and does not delete previously added records; therefore\nwe added a ",(0,a.jsx)(n.code,{children:"PRIMARY KEY"})," constraint to the table, making sure\nthat new updates overwrite existing entries in ",(0,a.jsx)(n.code,{children:"PRICE"})," for the same part and vendor ids."]})}),"\n",(0,a.jsxs)(n.p,{children:["Let's start the pipeline and inspect its output in the ",(0,a.jsx)(n.code,{children:"Change Stream"})," tab in the WebConsole. You should see\nchanges in ",(0,a.jsx)(n.code,{children:"PREFERRED_VENDOR"})," view approximately every second."]}),"\n",(0,a.jsxs)(n.p,{children:["To summarize Part 4 of the tutorial, we can attach a random generator to Feldera tables to simulate different scenarios\nsuch as backfill, continuous evaluation or a combination of the two.\nYou'll find a complete datagen reference in the ",(0,a.jsx)(n.a,{href:"../../connectors/sources/datagen",children:"connectors section"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var r=t(96540);const a={},i=r.createContext(a);function s(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);