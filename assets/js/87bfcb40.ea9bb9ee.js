"use strict";(self.webpackChunkfeldera_docs=self.webpackChunkfeldera_docs||[]).push([[4887],{21692:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"connectors/sinks/snowflake","title":"Snowflake output connector (experimental)","description":"The Feldera Snowflake connector ingests data change events produced by a Feldera","source":"@site/docs/connectors/sinks/snowflake.md","sourceDirName":"connectors/sinks","slug":"/connectors/sinks/snowflake","permalink":"/connectors/sinks/snowflake","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"PostgreSQL","permalink":"/connectors/sinks/postgresql"},"next":{"title":"File","permalink":"/connectors/sinks/file"}}');var s=a(74848),o=a(28453);const r={},i="Snowflake output connector (experimental)",c={},l=[{value:"Architecture",id:"architecture",level:2},{value:"Terminology",id:"terminology",level:2},{value:"Configure Snowflake",id:"configure-snowflake",level:2},{value:"Create landing tables",id:"create-landing-tables",level:2},{value:"Create the data ingestion task",id:"create-the-data-ingestion-task",level:2},{value:"Create a Kafka Connector for Snowflake",id:"create-a-kafka-connector-for-snowflake",level:2},{value:"Create Feldera Snowflake connector",id:"create-feldera-snowflake-connector",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Is the Kafka connector in the <code>RUNNING</code> state?",id:"is-the-kafka-connector-in-the-running-state",level:3},{value:"Is data being produced to the Kafka topic?",id:"is-data-being-produced-to-the-kafka-topic",level:3},{value:"Is the data ingestion task running in Snowflake?",id:"is-the-data-ingestion-task-running-in-snowflake",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"snowflake-output-connector-experimental",children:"Snowflake output connector (experimental)"})}),"\n",(0,s.jsx)(n.p,{children:"The Feldera Snowflake connector ingests data change events produced by a Feldera\npipeline into a Snowflake database in near-realtime."}),"\n",(0,s.jsxs)(n.p,{children:["Because this connector uses the ",(0,s.jsx)(n.a,{href:"kafka",children:"Kafka output adapter"}),", it\nsupports ",(0,s.jsx)(n.a,{href:"/pipelines/fault-tolerance",children:"fault tolerance"})," too."]}),"\n",(0,s.jsx)(n.admonition,{title:"Experimental feature",type:"caution",children:(0,s.jsx)(n.p,{children:"Snowflake support is an experimental feature of Feldera."})}),"\n",(0,s.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsxs)(n.p,{children:["We use the ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/user-guide/kafka-connector",children:"Snowflake Connector for\nKafka"})," to stream changes\nfrom Feldera to Snowflake with low latency."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Feldera outputs a stream of changes to a table or view to a Kafka topic."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["The Snowflake Connector for Kafka reads the changes from Kafka and pushes them to a\nSnowflake ",(0,s.jsx)(n.strong,{children:"landing table"})," using the Snowpipe Streaming API.  The landing table can\nbe seen as a change log containing a sequence of insert and delete commands to\nbe applied to the ",(0,s.jsx)(n.strong,{children:"target table"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"A periodic data ingestion task removes updates buffered in the landing tables\nand applies them to the target tables."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"terminology",children:"Terminology"}),"\n",(0,s.jsx)(n.p,{children:"We use the following terms throughput this document."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Target schema"}),": a Snowflake schema that contains one or more target tables,\ni.e., tables that are the final recipients of updates from Feldera.  We use the\n",(0,s.jsx)(n.code,{children:"&{schema}"})," variable in SQL scripts below to refer to the target schema.  For\nsimplicity, the instructions below assume a single target schema, but they can\nbe easily adapted for multiple schemas."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Landing schema"}),": a Snowflake schema that contains intermediate tables\nthat store data change events until they are ingested\ninto the target tables.  Below we assume that the landing schema is called\n",(0,s.jsx)(n.code,{children:"&{schema}_landing"}),", but the user can choose any other name for it."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The Feldera user"}),": a Snowflake user account used by the Feldera Snowflake\nconnector to stream data change events to Snowflake.  This account\nmust be configured with read/write access to the landing schema.  It does not\nrequire access to the target schema."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"configure-snowflake",children:"Configure Snowflake"}),"\n",(0,s.jsxs)(n.p,{children:["Run the following SQL commands to create the landing schema in the\nsame database that stores the target schema.  We assume that the ",(0,s.jsx)(n.code,{children:"&{db}"}),"\nand ",(0,s.jsx)(n.code,{children:"&{schema}"})," variables contain respectively the name of the database and\nthe target schema."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"!set variable_substitution=true\n\n-- Create a schema for landing tables.\nUSE ROLE accountadmin;\nCREATE SCHEMA IF NOT EXISTS &{db}.&{schema}_landing;\n\n-- Create a role and a user account that Feldera will use\n-- to access the landing schema.\nUSE ROLE securityadmin;\n\nCREATE ROLE IF NOT EXISTS feldera;\nGRANT ALL ON SCHEMA &{db}.&{schema}_landing TO ROLE feldera;\n\nCREATE USER IF NOT EXISTS feldera;\nGRANT ROLE feldera TO USER feldera;\nALTER USER feldera SET DEFAULT_ROLE = feldera;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Follow ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/key-pair-auth",children:"Snowflake documentation"}),"\nto setup private key authentication for the ",(0,s.jsx)(n.code,{children:"feldera"})," user."]}),"\n",(0,s.jsx)(n.h2,{id:"create-landing-tables",children:"Create landing tables"}),"\n",(0,s.jsxs)(n.p,{children:["Create a landing table for each target table.  The landing table has the same\ncolumns as the target, but none of its constraints (",(0,s.jsx)(n.code,{children:"UNIQUE"}),", ",(0,s.jsx)(n.code,{children:"PRIMARY KEY"}),",\n",(0,s.jsx)(n.code,{children:"FOREIGN KEY"}),", ",(0,s.jsx)(n.code,{children:"DEFAULT"}),", ",(0,s.jsx)(n.code,{children:"NOT NULL"}),").  It also contains several metadata columns\nused by Feldera to apply updates in the correct order."]}),"\n",(0,s.jsxs)(n.p,{children:["For example, given a target table ",(0,s.jsx)(n.code,{children:"t1"})," with the following definition:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE t1 (\n    id NUMBER NOT NULL PRIMARY KEY,\n    seq NUMBER DEFAULT seq1.NEXTVAL,\n    foreign_id NUMBER,\n    FOREIGN KEY (foreign_id) REFERENCES other_table(id)\n);\n"})}),"\n",(0,s.jsx)(n.p,{children:"we create the following table in the landing schema:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"!set variable_substitution=true\n\nUSE SCHEMA &{db}.&{schema}_landing;\n\nCREATE TABLE t1 (\n    -- Columns from the target table with all constraints removed.\n    id NUMBER,\n    seq NUMBER,\n    foreign_id NUMBER,\n\n    -- Additional metadata columns.\n    __action STRING NOT NULL,\n    __stream_id NUMBER NOT NULL,\n    __seq_number NUMBER NOT NULL,\n    UNIQUE (__stream_id, __seq_number)\n)\n-- Required by Snowpipe Streaming.\nENABLE_SCHEMA_EVOLUTION=TRUE;\n\n-- Create a Snowflake stream to track changes\n-- to the landing table.\nCREATE STREAM T1_STREAM ON TABLE T1 APPEND_ONLY = TRUE;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The last statement in this snippet attaches a\n",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/streams-intro",children:"Snowflake stream"}),"\nto the landing table.  This stream will be used by\nthe data ingestion task to track changes to the table."]}),"\n",(0,s.jsx)(n.h2,{id:"create-the-data-ingestion-task",children:"Create the data ingestion task"}),"\n",(0,s.jsx)(n.admonition,{type:"caution",children:(0,s.jsx)(n.p,{children:"For the data ingestion process to work correctly, the output views computed\nby Feldera must respect constraints defined for the target table in Snowflake.\nFor example, if the target table defines a primary or a unique key constraint,\nthen the corresponding view computed by Feldera should never contain more than\none record with the same value of the key columns."})}),"\n",(0,s.jsxs)(n.p,{children:["Create a data ingestion task to periodically\napply updates buffered in the landing tables to the target tables.\nThe role used to execute this SQL script must have write privileges\nfor both the landing and the target tables, as well as\nthe privileges listed in\n",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/sql-reference/sql/create-task#access-control-requirements",children:"Snowflake Access Control requirements"}),"\nfor task creation.  In addition, if the user chooses to run the\ntask in the ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/tasks-intro#serverless-tasks",children:"serverless mode"}),"\nthe role must have the ",(0,s.jsx)(n.code,{children:"EXECUTE MANAGED TASK"})," privilege."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"!set variable_substitution=true\n\nUSE SCHEMA &{db}.&{schema}_landing;\n\n!set sql_delimiter=/\n\nCREATE TASK INGEST_DATA\n  -- Run the task once a minute.\n  SCHEDULE = '1 minute'\n  -- By not specifying a warehouse in which to run the task, we\n  -- opt for the serverless model (requires the `EXECUTE MANAGED TASK`\n  -- privilege).  Uncomment the following line in order to run the\n  -- task in a user-managed warehouse instead.\n  --WAREHOUSE = <your_warehouse_name>\n  WHEN\n    ((SYSTEM$STREAM_HAS_DATA('T1_STREAM'))\n    -- When synchronizing multiple tables, add a clause for each additional table below\n    -- or (SYSTEM$STREAM_HAS_DATA('<table>_STREAM')))\n  AS\n    BEGIN\n        START TRANSACTION;\n\n        -- Merge data from the stream into the target table.\n        MERGE INTO &{schema}.T1 AS T\n        USING (\n            SELECT * FROM T1_STREAM where (__stream_id, __seq_number)\n                in (SELECT __stream_id, max(__seq_number) as __seq_number\n                    FROM PRICE_STREAM GROUP BY (id, __stream_id))\n        ) AS S ON (T.id = S.id)\n        WHEN MATCHED AND S.__action = 'delete' THEN\n            DELETE\n        WHEN MATCHED AND S.__action = 'insert' THEN\n            UPDATE SET T.seq = S.seq, T.foreign_id = S.foreign_id\n        WHEN NOT MATCHED AND S.__action = 'insert' THEN\n            INSERT (id, seq, foreign_id)\n            VALUES (S.id, S.seq, S.foreign_id);\n\n        -- Delete ingested records from the landing table.\n        DELETE from T1 WHERE (__stream_id, __seq_number) in (SELECT __stream_id, __seq_number FROM T1_STREAM);\n\n        COMMIT;\n    END;/\n\n!set sql_delimiter=\";\"\n\n-- Start running the task periodically.\nALTER TASK ingest_data RESUME;\n"})}),"\n",(0,s.jsx)(n.h2,{id:"create-a-kafka-connector-for-snowflake",children:"Create a Kafka Connector for Snowflake"}),"\n",(0,s.jsx)(n.p,{children:"Use the Kafka Connect REST API to create a Snowflake Connector\nconfigured to read data change events from a set of Kafka topics and store them\nin the landing tables."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST <kafka_connect_url> -d \'{\n    "name": "my-snowflake-connector",\n    "config": {\n        "connector.class": "com.snowflake.kafka.connector.SnowflakeSinkConnector",\n        "tasks.max": "8",\n        "topics": "snowflake.t1",\n        "snowflake.topic2table.map": "snowflake.t1:t1",\n        "errors.tolerance": "none",\n        "snowflake.ingestion.method": "SNOWPIPE_STREAMING",\n        "snowflake.enable.schematization": "TRUE",\n        "key.converter": "org.apache.kafka.connect.storage.StringConverter",\n        "value.converter": "org.apache.kafka.connect.json.JsonConverter",\n        "value.converter.schemas.enable": "false",\n        "snowflake.url.name": "<account_name>.snowflakecomputing.com:443",\n        "snowflake.user.name": "feldera",\n        "snowflake.role.name": "feldera",\n        "snowflake.private.key": <private_key>,\n        "snowflake.private.key.passphrase": <passphrase>,\n        "snowflake.database.name": <database_name>,\n        "snowflake.schema.name": <landing_schema>,\n        "buffer.flush.time": "1",\n        "max.poll.interval.ms": "10000",\n        "buffer.count.records": "10000",\n    }\n}\'\n'})}),"\n",(0,s.jsxs)(n.p,{children:["We explain the configuration options below.\nSee also ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/kafka-connector-install#configuring-the-kafka-connector",children:"Kafka Connector for Snowflake documentation"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"topics"})," - comma-separate list of Kafka topics to read from, with one topic per table."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.topic2table.map"})," - comma-separated list of Kafka topic names to table name mappings."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"errors.tolerance"})," - determines how many parsing errors the connector can accept before\ngoing into the failed state.  Setting this parameter to ",(0,s.jsx)(n.code,{children:"none"})," will cause the connector to\nstop after encountering the first error, giving the operator a chance to fix the problem\nbefore restarting the connector. Setting it to ",(0,s.jsx)(n.code,{children:"all"})," configures the connector to continue\nworking after encountering any number of invalid Kafka messages.  If you choose this\noption, we strongly recommend enabling the ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-kafka#dead-letter-queues",children:"Dead Letter Queues"}),"\nfeature in order to record problematic messages in a separate Kafka topic."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.ingestion.method"})," - must be set to ",(0,s.jsx)(n.code,{children:"SNOWPIPE_STREAMING"})," to load data into\nSnowflake using ",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-kafka",children:"Snowpipe Streaming"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.enable.schematization"})," - must be set to ",(0,s.jsx)(n.code,{children:"TRUE"})," to ingest data into strongly\ntype columns rather than storing it as raw JSON objects."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.url.name"})," - URL for accessing your Snowflake account, which has the following\nformat: ",(0,s.jsx)(n.code,{children:"<account_name>.snowflakecomputing.com:443"}),", where ",(0,s.jsx)(n.code,{children:"<account_name>"})," is an account\nidentifier for an account in your organization using the\n",(0,s.jsxs)(n.a,{href:"https://docs.snowflake.com/en/user-guide/admin-account-identifier#using-an-account-name-as-an-identifier",children:[(0,s.jsx)(n.code,{children:"<orgname>-<account_name>"})," format"]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.user.name"})," - Snowflake user account created for the Feldera Snowflake connector\nduring the ",(0,s.jsx)(n.a,{href:"#configure-snowflake",children:"Snowflake Configuration step"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.role.name"})," - Snowflake role created for the Feldera Snowflake connector\nduring the ",(0,s.jsx)(n.a,{href:"#configure-snowflake",children:"Snowflake Configuration step"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.private.key"})," - private key created for the Feldera user by following\n",(0,s.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/key-pair-auth",children:"Snowflake documentation"}),".\nInclude only the key, not the header or footer. If the key is split across multiple\nlines, remove the line breaks. You can provide an unencrypted key, or you can provide\nan encrypted key and provide the ",(0,s.jsx)(n.code,{children:"snowflake.private.key.passphrase"})," parameter to\nenable Snowflake to decrypt the key."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.private.key.passphrase"})," - specify this parameter when using an encrypted\nprivate key.  The connector will use this string to decrypt the password."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.database.name"})," - Snowflake database that contains the landing schema\n(see ",(0,s.jsx)(n.a,{href:"#create-landing-tables",children:"Create Landing Tables"}),")."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"snowflake.schema.name"})," - landing schema name\n(see ",(0,s.jsx)(n.a,{href:"#create-landing-tables",children:"Create Landing Tables"}),")."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"buffer.flush.time"})," - maximum number of seconds the connector will buffer Kafka messages\nbefore sending them to Snowflake.  The default value is 120 seconds."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"buffer.count.records"})," - maximum number of Kafka messages buffered by the connector."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"max.poll.interval.ms"})," - determines the frequency with which the connector polls\nKafka for new messages."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"create-feldera-snowflake-connector",children:"Create Feldera Snowflake connector"}),"\n",(0,s.jsxs)(n.p,{children:["The Snowflake connector uses a Kafka output transport, so the specification\nof the connector is the same as for ",(0,s.jsx)(n.a,{href:"/connectors/sinks/kafka",children:"Kafka outputs"}),".\nFor example, in the view declaration we can specify the connector properties:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'CREATE VIEW V AS ...\nWITH (\n   \'connectors\' = \'[{\n      "transport": {\n          "name": "kafka_output",\n          "config": {\n              "bootstrap.servers": "redpanda:9092",\n              "topic": "snowflake.price",\n              "security.protocol": "plaintext"\n          }\n      },\n      "format": {\n          "name": "json",\n          "config": {\n              "update_format": "insert_delete",\n              "array": false\n          }\n      }\n   }]\'\n)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["As you start the pipeline, updates to the output view attached to the Snowflake\nconnector should get ingested into Snowflake and appear in your target tables.\nThe end-to-end ingestion latency is currently bounded by the frequency of running\nthe data ingestion task, e.g., 1 minute in the ",(0,s.jsx)(n.a,{href:"#create-the-data-ingestion-task",children:"example"}),"\nabove."]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.p,{children:"There are several things you can check if the data does not show up in the target tables."}),"\n",(0,s.jsxs)(n.h3,{id:"is-the-kafka-connector-in-the-running-state",children:["Is the Kafka connector in the ",(0,s.jsx)(n.code,{children:"RUNNING"})," state?"]}),"\n",(0,s.jsxs)(n.p,{children:["Check that the Snowflake Kafka connector is running by polling its ",(0,s.jsx)(n.code,{children:"/status"}),"\nendpoint.  The connector can fail due to a misconfiguration or invalid input data."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"curl -X GET <kafka-connect-server>/connectors/<snowflake-connector-name>/status\n"})}),"\n",(0,s.jsx)(n.h3,{id:"is-data-being-produced-to-the-kafka-topic",children:"Is data being produced to the Kafka topic?"}),"\n",(0,s.jsxs)(n.p,{children:["Check that the pipeline outputs data change events to the Kafka topic.  For\ninstance, using Redpanda as a Kafka broker and the ",(0,s.jsx)(n.code,{children:"rpk"})," command line utility:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"rpk topic consume <topic_name>\n"})}),"\n",(0,s.jsx)(n.h3,{id:"is-the-data-ingestion-task-running-in-snowflake",children:"Is the data ingestion task running in Snowflake?"}),"\n",(0,s.jsx)(n.p,{children:"Use the following Snowflake SQL command to retrieve the list\nof tasks in the landing schema."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SHOW TASKS in <db>.<landing_schema_name>;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Make sure that the data ingestion task is in the ",(0,s.jsx)(n.code,{children:"started"})," state."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>i});var t=a(96540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);